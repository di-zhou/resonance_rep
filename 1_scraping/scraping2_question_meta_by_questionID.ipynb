{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get question meta-data for a given question ID\n",
    "\n",
    "### About this script:\n",
    "* **Input**: A list of question ID\n",
    "* **Output**: A list of question meta-data by question ID: Question Text, Answer Count, Follower Count, View Count, Tags\n",
    "\n",
    "### General info:\n",
    "* **Forum**: https://www.zhihu.com/ (Sign-up required)\n",
    "* **References**: https://blog.csdn.net/wenxuhonghe/article/details/86515558; https://blog.csdn.net/wenxuhonghe/article/details/107122978 --I want to thank the code creator, 机灵鹤 (\"Smart Crane\"), for answering my questions about modifying his code for my own project!\n",
    "* **Author**: Di Zhou (NYU Sociology)\n",
    "* **Last Run**: Dec. 2020 \n",
    "* **Disclaimer**: The forum constantly updates its security and webpage information architecture. This scraping code and its reference may need modifications in order to scrape data from the forum when you access it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_question_data(q_id):\n",
    "\n",
    "    headers = {\n",
    "        'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "        'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Safari/537.36',\n",
    "    }\n",
    "    \n",
    "    url = 'https://www.zhihu.com/question/' + str(q_id)\n",
    "    \n",
    "    try:\n",
    "        r = requests.get(url, headers = headers)\n",
    "        r.raise_for_status()\n",
    "        bsobj = bs(r.text, 'lxml')\n",
    "        \n",
    "        qContent = bsobj.find_all('meta', attrs={'itemprop':'name'})[0]['content']\n",
    "        followerCount = bsobj.find_all('strong', attrs={'class':'NumberBoard-itemValue'})[0]['title']\n",
    "        viewCount = bsobj.find_all('strong', attrs={'class':'NumberBoard-itemValue'})[1]['title']\n",
    "        answerCount = bsobj.find_all('meta', attrs={'itemprop':'answerCount'})[0]['content']\n",
    "        topicTag = bsobj.find_all('meta', attrs={'itemprop':'keywords'})[0]['content']\n",
    "        \n",
    "        return [q_id, qContent, followerCount, viewCount, answerCount, topicTag]\n",
    "    \n",
    "    except requests.HTTPError as e:\n",
    "        print(e)\n",
    "        print(\"HTTPError\")\n",
    "        return [q_id, e, e, e, e, e]\n",
    "    \n",
    "    except requests.RequestException as e:\n",
    "        print(e)\n",
    "        return [q_id, e, e, e, e, e]\n",
    "    \n",
    "    except:\n",
    "        print(\"Unknown Error !\")\n",
    "        return [q_id, \"UnknownError\", \"UnknownError\", \"UnknownError\", \"UnknownError\", \"UnknownError\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(q_info_list):\n",
    "    filename = 'data/q_meta.csv'\n",
    "    dataframe = pd.DataFrame(q_info_list)\n",
    "    # dataframe.to_csv(filename, mode='a', index=False, sep=',', header=False)\n",
    "    dataframe.to_csv(filename, mode='a', index=False, sep=',', header=['q_id','q_content','followerCount','viewCount', 'answerCount', 'topicTag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_list(q_info_list):\n",
    "    with open('data/q_meta.data', 'wb') as filehandle:\n",
    "        pickle.dump(q_info_list, filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import csv (a list of Question ID), convert to list\n",
    "df = pd.read_csv('data/q_list.csv')  \n",
    "q_list = df.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A loop that run all questions\n",
    "def main():\n",
    "    \n",
    "    q_info_list = []    \n",
    "    \n",
    "    for i in range(len(q_list)): \n",
    "        q_id = q_list[i][0]\n",
    "        print('working on', 'question', i+1 , ': ', q_list[i][0], q_list[i][7])\n",
    "        q_info_list.append(get_question_data(q_id))\n",
    "    try:\n",
    "        save_data(q_info_list)\n",
    "    except:\n",
    "        save_list(q_info_list)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    print(\"Finish！！\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
